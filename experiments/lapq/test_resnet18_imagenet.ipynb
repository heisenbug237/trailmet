{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../../trailmet/algorithms/quantize/'\n",
      "/home/akash/Documents/trailmet/trailmet/algorithms/quantize\n"
     ]
    }
   ],
   "source": [
    "cd \"../../trailmet/algorithms/quantize/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms \u001b[39mas\u001b[39;00m transforms\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets \u001b[39mas\u001b[39;00m datasets\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms as transforms\n",
    "from torchvision import datasets as datasets\n",
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imagenet_data(data_path: str = '', input_size: int = 224, batch_size: int = 64, workers: int = 4,\n",
    "                        dist_sample: bool = False):\n",
    "    print('==> Using Imagenet Dataset')\n",
    "\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    #torchvision.set_image_backend('accimage')\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    if dist_sample:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=workers, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,batch_size=batch_size, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True, sampler=val_sampler)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using Imagenet Dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# load data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=1'>2</a>\u001b[0m dataloaders \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:[], \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m:[]}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=2'>3</a>\u001b[0m dataloaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], dataloaders[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m build_imagenet_data(data_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/workspace/code/Akash/ImageNet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb Cell 5\u001b[0m in \u001b[0;36mbuild_imagenet_data\u001b[0;34m(data_path, input_size, batch_size, workers, dist_sample)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=4'>5</a>\u001b[0m traindir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=5'>6</a>\u001b[0m valdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=6'>7</a>\u001b[0m normalize \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=7'>8</a>\u001b[0m                                  std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39m#torchvision.set_image_backend('accimage')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=10'>11</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mImageFolder(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=11'>12</a>\u001b[0m     traindir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=12'>13</a>\u001b[0m     transforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=16'>17</a>\u001b[0m         normalize,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000003?line=17'>18</a>\u001b[0m     ]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataloaders = {'train':[], 'val':[]}\n",
    "dataloaders['train'], dataloaders['val'] = build_imagenet_data(data_path='/workspace/code/Akash/ImageNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m# import libraries\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrailmet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrailmet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbrecq\u001b[39;00m \u001b[39mimport\u001b[39;00m BRECQ\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akash/Documents/trailmet/experiments/lapq/test_resnet18_imagenet.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrailmet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantize\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseQuantization\n",
      "File \u001b[0;32m~/Documents/trailmet/trailmet/algorithms/quantize/../../../trailmet/models/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m get_resnet_model\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtest_resnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtest_inception\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/trailmet/trailmet/algorithms/quantize/../../../trailmet/models/resnet.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m load_state_dict_from_url\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_model\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from trailmet.models import resnet\n",
    "from trailmet.algorithms.quantize.lapq import LAPQ\n",
    "from trailmet.algorithms.quantize.quantize import BaseQuantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "cnn = resnet.get_resnet_model('resnet18', 1000, 224, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f4fa6b9b847b7a948ccad8d9ccc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80.53082833429231, 95.22303150693048, 0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test full precision model\n",
    "bq = BaseQuantization()\n",
    "bq.test(model=cnn, dataloader=dataloaders['val'], device=torch.device('cuda:7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting the first and the last layer to 8-bit\n",
      "==> Initializing weight quantization parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac649b13b4774a40adb2c93982e5721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized accuracy before brecq: (55.30476949069481, 77.8277628010717, 0.0)\n",
      "==> Starting weight calibration\n",
      "Ignore reconstruction of layer conv1\n",
      "Reconstruction for block 0\n",
      "Total loss:\t483.689 (rec:0.644, round:483.046)\tb=13.25\tcount=1000\n",
      "Total loss:\t199.292 (rec:0.959, round:198.333)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t509.780 (rec:40.379, round:469.401)\tb=13.25\tcount=1000\n",
      "Total loss:\t254.552 (rec:37.905, round:216.647)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t489.750 (rec:42.663, round:447.087)\tb=13.25\tcount=1000\n",
      "Total loss:\t222.848 (rec:45.072, round:177.776)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t2423.465 (rec:53.310, round:2370.155)\tb=13.25\tcount=1000\n",
      "Total loss:\t964.340 (rec:54.799, round:909.542)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t1784.104 (rec:65.987, round:1718.117)\tb=13.25\tcount=1000\n",
      "Total loss:\t705.271 (rec:62.737, round:642.534)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t1730.266 (rec:62.453, round:1667.812)\tb=13.25\tcount=1000\n",
      "Total loss:\t647.936 (rec:68.672, round:579.264)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t1717.029 (rec:64.733, round:1652.296)\tb=13.25\tcount=1000\n",
      "Total loss:\t621.296 (rec:62.083, round:559.213)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t9100.884 (rec:79.949, round:9020.936)\tb=13.25\tcount=1000\n",
      "Total loss:\t3268.855 (rec:87.997, round:3180.858)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t6737.598 (rec:92.696, round:6644.901)\tb=13.25\tcount=1000\n",
      "Total loss:\t2383.212 (rec:93.342, round:2289.870)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t6597.418 (rec:94.655, round:6502.763)\tb=13.25\tcount=1000\n",
      "Total loss:\t2218.584 (rec:96.477, round:2122.106)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t6663.128 (rec:93.480, round:6569.649)\tb=13.25\tcount=1000\n",
      "Total loss:\t2311.036 (rec:96.312, round:2214.723)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 4\n",
      "Total loss:\t6624.605 (rec:90.966, round:6533.640)\tb=13.25\tcount=1000\n",
      "Total loss:\t2267.580 (rec:91.079, round:2176.501)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 5\n",
      "Total loss:\t6476.241 (rec:73.114, round:6403.127)\tb=13.25\tcount=1000\n",
      "Total loss:\t2101.043 (rec:77.540, round:2023.504)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t37723.527 (rec:226.098, round:37497.430)\tb=13.25\tcount=1000\n",
      "Total loss:\t14768.767 (rec:211.116, round:14557.650)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t27417.434 (rec:134.422, round:27283.012)\tb=13.25\tcount=1000\n",
      "Total loss:\t10120.478 (rec:127.697, round:9992.780)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t26752.529 (rec:58.369, round:26694.160)\tb=13.25\tcount=1000\n",
      "Total loss:\t9204.546 (rec:54.544, round:9150.002)\tb=2.00\tcount=2000\n",
      "Reconstruction for layer fc\n",
      "Total loss:\t10456.123 (rec:6.751, round:10449.372)\tb=13.25\tcount=1000\n",
      "Total loss:\t2415.106 (rec:7.796, round:2407.310)\tb=2.00\tcount=2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90775c6089764e348f7e00657c53c0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight quantization accuracy: (80.07952153334884, 95.056438122251, 0.0)\n",
      "Ignore reconstruction of layer conv1\n",
      "Reconstruction for block 0\n",
      "Total loss:\t73.976 (rec:73.976, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t72.456 (rec:72.456, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t62.294 (rec:62.294, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t61.987 (rec:61.987, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t23.575 (rec:23.575, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t23.473 (rec:23.473, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t89.514 (rec:89.514, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t92.396 (rec:92.396, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t35.816 (rec:35.816, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t36.481 (rec:36.481, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t17.994 (rec:17.994, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t26.201 (rec:26.201, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t9.724 (rec:9.724, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t9.844 (rec:9.844, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t55.644 (rec:55.644, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t64.112 (rec:64.112, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t27.418 (rec:27.418, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t27.929 (rec:27.929, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t13.698 (rec:13.698, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t12.806 (rec:12.806, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t15.495 (rec:15.495, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t16.074 (rec:16.074, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 4\n",
      "Total loss:\t13.783 (rec:13.783, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t12.862 (rec:12.862, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 5\n",
      "Total loss:\t6.729 (rec:6.729, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t6.629 (rec:6.629, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t93.077 (rec:93.077, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t101.052 (rec:101.052, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t39.584 (rec:39.584, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t37.288 (rec:37.288, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t29.225 (rec:29.225, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t31.139 (rec:31.139, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for layer fc\n",
      "Total loss:\t0.193 (rec:0.193, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t0.320 (rec:0.320, round:0.000)\tb=0.00\tcount=2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef79053a6ab46ca8b15071d04873be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full quantization (W4A8) accuracy: (80.08159381451594, 94.97354687556664, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# quantize model\n",
    "kwargs = {\n",
    "    'ACT_QUANT':True, \n",
    "    'NUM_SAMPLES':1024, \n",
    "    'ITERS_W':2000, \n",
    "    'ITERS_A':2000, \n",
    "    'cal_batch_size':256, \n",
    "    'GPU_ID':7,\n",
    "    'pretrained':True,\n",
    "    'min_method': 'Powell',\n",
    "    'maxiter' : 2,\n",
    "    'bit_act' : 4,\n",
    "    'bit_weight' : 4\n",
    "    }\n",
    "lapq = LAPQ(cnn, dataloaders, **kwargs)\n",
    "lapq.compress_model()\n",
    "\n",
    "# increase iterations from 2000 to 20000 to achieve full optimization potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 15 19:23:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   212W / 300W |  31301MiB / 32510MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   199W / 300W |    670MiB / 32510MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    56W / 300W |   3576MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   188W / 300W |    670MiB / 32510MiB |     94%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    55W / 300W |   1422MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    41W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    54W / 300W |   9212MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    54W / 300W |   4306MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
