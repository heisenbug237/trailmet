{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "498871cf",
      "metadata": {
        "id": "498871cf"
      },
      "source": [
        "## LAPQ\n",
        "This notebook demonstrates the implimentation of the paper [Loss Aware Post-training Quantization](https://arxiv.org/abs/1911.07190)\n",
        "\n",
        "### Steps to quantize the pretrained model\n",
        "- Load the dataset and create dataloader. A subset of training data is used for calibration.\n",
        "- Load the pretrained full precision model.\n",
        "- Load the configurations from the YAML file.\n",
        "- Create a `LAPQ` object and pass the full precision model, dataloaders and configurations.\n",
        "- Quantize the model by calling the `compress_model` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_COLAB = True\n",
        "\n",
        "if USE_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")\n",
        "  base_path = \"/content/drive/MyDrive/trail\"\n",
        "else:\n",
        "  base_path = \"../../../..\"\n",
        "\n",
        "library_path = base_path + \"/trailmet\"\n",
        "requirements_path = library_path + \"/requirements.txt\"\n",
        "config_path = library_path + \"/experiments/quantization/LAPQ/lapq_config.yaml\"\n",
        "weights_path = base_path + \"/weights/resnet50_cifar100_pretrained.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skKWRRtMsfRM",
        "outputId": "ada0dc11-61c2-4637-cf0e-a4f25ad28b3c"
      },
      "id": "skKWRRtMsfRM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -r $requirements_path"
      ],
      "metadata": {
        "id": "P7Kar046xSEd"
      },
      "id": "P7Kar046xSEd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dafbd1b3",
      "metadata": {
        "id": "dafbd1b3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(library_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417e9692",
      "metadata": {
        "id": "417e9692"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "from trailmet.models import resnet, mobilenet\n",
        "from trailmet.algorithms import quantize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67e2359",
      "metadata": {
        "id": "c67e2359"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a12f9a",
      "metadata": {
        "id": "64a12f9a"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8c6192",
      "metadata": {
        "id": "4c8c6192"
      },
      "outputs": [],
      "source": [
        "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(*stats, inplace=True)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(*stats)\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(*stats)\n",
        "])\n",
        "\n",
        "input_transforms = {\n",
        "    'train': train_transform,\n",
        "    'val': val_transform,\n",
        "    'test': test_transform}\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None,\n",
        "    'val': None,\n",
        "    'test': None}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c41f2b1",
      "metadata": {
        "id": "0c41f2b1"
      },
      "source": [
        "### Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b377f3bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b377f3bb",
        "outputId": "3e9a49d0-bdcf-45d7-f79d-714f81395080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13715362.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train samples:  40000\n",
            "Val samples:  10000\n",
            "Test samples:  10000\n"
          ]
        }
      ],
      "source": [
        "cifar100_dataset = DatasetFactory.create_dataset(\n",
        "        name = 'CIFAR100',\n",
        "        root = './data',\n",
        "        split_types = ['train', 'val', 'test'],\n",
        "        val_fraction = 0.2,\n",
        "        transform = input_transforms,\n",
        "        target_transform = target_transforms)\n",
        "\n",
        "# getting the size of the different splits\n",
        "print('Train samples: ',cifar100_dataset['info']['train_size'])\n",
        "print('Val samples: ',cifar100_dataset['info']['val_size'])\n",
        "print('Test samples: ',cifar100_dataset['info']['test_size'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec91853",
      "metadata": {
        "id": "eec91853"
      },
      "source": [
        "### Define Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464c2e93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464c2e93",
        "outputId": "499a7028-ebe1-4b26-89ba-3206fda6c59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of training batches:  313\n",
            "No. of validation batches:  79\n",
            "No. of test batches:  79\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(\n",
        "        cifar100_dataset['train'], batch_size=128,\n",
        "        sampler=cifar100_dataset['train_sampler'],\n",
        "        num_workers=0)\n",
        "val_loader = DataLoader(\n",
        "        cifar100_dataset['val'], batch_size=128,\n",
        "        sampler=cifar100_dataset['val_sampler'],\n",
        "        num_workers=0)\n",
        "test_loader = DataLoader(\n",
        "        cifar100_dataset['test'], batch_size=128,\n",
        "        sampler=cifar100_dataset['test_sampler'],\n",
        "        num_workers=0)\n",
        "\n",
        "dataloaders = {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
        "\n",
        "print('No. of training batches: ', len(dataloaders['train']))\n",
        "print('No. of validation batches: ', len(dataloaders['val']))\n",
        "print('No. of test batches: ', len(dataloaders['test']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85812739",
      "metadata": {
        "id": "85812739"
      },
      "source": [
        "### Load Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4db07ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4db07ac",
        "outputId": "c7625367-ce16-4139-a7f1-9b50369ccfe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model = resnet.make_resnet50(100,32)\n",
        "checkpoint = torch.load(weights_path, map_location='cuda:0')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca3e796",
      "metadata": {
        "id": "0ca3e796"
      },
      "source": [
        "### Load Method Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9625ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9625ad",
        "outputId": "e34c1fe3-1037-4460-afe8-eb67d5599600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GPU_ID': 0,\n",
              " 'SEED': 42,\n",
              " 'W_BITS': 7,\n",
              " 'A_BITS': 7,\n",
              " 'ACT_QUANT': True,\n",
              " 'CALIB_BATCHES': 4,\n",
              " 'MAX_ITER': 2000,\n",
              " 'MAX_FEV': 2000,\n",
              " 'VERBOSE': True}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "    kwargs = config['GENERAL']\n",
        "\n",
        "kwargs['MAX_ITER']=2000\n",
        "kwargs['MAX_FEV']=2000\n",
        "kwargs['A_BITS']=7\n",
        "kwargs['W_BITS']=7\n",
        "\n",
        "kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87e6c554",
      "metadata": {
        "id": "87e6c554"
      },
      "source": [
        "### Quantization Method: LAPQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21d5073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e21d5073",
        "outputId": "50e0b908-b8a7-49f4-93e4-e11fd6752220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Using seed: 42 and device: cuda:0\n",
            "testing pretrained model before quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:10<00:00,  7.57it/s, acc1=72.5, acc5=91.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top-1 acc: 72.52%, top-5 acc: 91.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:08<00:00,  8.84it/s, acc1=69.5, acc5=90]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Quantization (W7A7) accuracy before LAPQ: 69.5115 | 90.0316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:20<00:00,  2.00s/it, loss=0.176, p_val=4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> using p val : 3.66  with lp-loss : 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:10<00:00,  7.89it/s, acc1=72.3, acc5=91.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Quantization (W7A7) accuracy before Optimization: 72.2508 | 91.3370\n",
            "==> Starting Powell Optimization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [09:21<00:00,  3.56it/s, curr_loss=0.176, min_loss=0.152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Layer-wise Scales :\n",
            " [ 0.33818299  0.62134768  0.82564299  1.02090729  0.95200617  0.36689557\n",
            "  0.56235786  0.83859347  0.14576932  0.61901607  1.22165686  0.47066361\n",
            "  0.26149886  0.74342126  0.45708764  0.14837253  0.15520184  1.14811294\n",
            "  0.17855284  0.39177551  1.10277545  0.2693316   0.21350731  0.71349451\n",
            "  0.36680011  0.12632736  0.51384439  0.2863148   0.12838054  0.18741796\n",
            "  0.85134318  0.10731246  0.16548798  0.66784387  0.09932491  0.16292682\n",
            "  0.85598874  0.12488759  0.20705417  0.68615477  0.18071352  0.27441487\n",
            "  0.54972186  0.30531706  0.2248336   1.19240661  0.4168146   0.04306774\n",
            "  0.33290503  0.80163794  0.01937079  0.19003982  0.72733849  0.34951356\n",
            "  1.99468306  1.23356115  0.83784936  0.51849612  0.43591889  0.5504359\n",
            "  0.84351204  0.81898661  0.38176331  0.57372303  0.48332823  0.81326441\n",
            "  0.30857745  0.38395615  0.6832149   0.65068425  0.63195158  0.52181466\n",
            "  0.65721197  0.64087668  0.65638089  0.24518578  0.48958696  0.70771214\n",
            "  0.7810806   0.36986201  0.37629303  0.68606285  0.71880917  0.48262717\n",
            "  0.45337911  0.37663389  0.68937862  0.7618183   0.55862383  0.57610431\n",
            "  0.47111681  0.6936263   0.32051978  0.35080028  0.6339107   0.80058439\n",
            "  0.34578153  0.34025314  0.3652297   0.80349561  0.35078868  0.34667977\n",
            "  0.51684356  0.97855669  0.35530103  0.43259362  0.493544    0.7734252\n",
            "  0.54179977  0.55423125  0.59282164  2.02728408  0.61292773  0.68140569\n",
            "  1.75588362  0.81362313  3.61825858  0.41211504  0.69931554  2.21552974\n",
            "  4.88437368  0.2972496   0.3892928   2.21019835 10.95171503]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:08<00:00,  9.15it/s, acc1=72, acc5=91.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Full quantization (W7A7) accuracy: (72.03322784810126, 91.18868670886076)\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.nn.quantized.modules.functional_modules.FloatFunctional'>: <class 'torch.ao.nn.quantized.modules.functional_modules.QFunctional'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.conv.Conv2d'>: <class 'torch.ao.nn.quantized.modules.conv.Conv2d'>\n",
            "swapped <class 'torch.ao.quantization.stubs.QuantStub'>: <class 'torch.ao.nn.quantized.modules.Quantize'>\n",
            "swapped <class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>: <class 'torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>\n",
            "swapped <class 'torch.nn.modules.linear.Linear'>: <class 'torch.ao.nn.quantized.modules.linear.Linear'>\n"
          ]
        }
      ],
      "source": [
        "quantizer = quantize.lapq.LAPQ(model, dataloaders, **kwargs)\n",
        "qmodel = quantizer.compress_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6edd9e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6edd9e9",
        "outputId": "1e9224a6-7bf5-42d2-cc44-0456a742bcfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing quantized model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:15<00:00,  1.04it/s, acc1=72.3, acc5=91.1]\n"
          ]
        }
      ],
      "source": [
        "print('testing quantized model')\n",
        "qmodel.to(torch.device('cpu'))\n",
        "acc1, acc5 = quantizer.test(model=qmodel, dataloader=dataloaders['test'], device=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('testing full precision model')\n",
        "model.to(torch.device('cpu'))\n",
        "acc1, acc5 = quantizer.test(model=model, dataloader=dataloaders['test'], device=torch.device('cpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMg5Wvv-P5Z9",
        "outputId": "083d9b2d-4845-4045-8fda-d1df44bdc509"
      },
      "id": "GMg5Wvv-P5Z9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing full precision model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [02:54<00:00,  2.21s/it, acc1=72.5, acc5=91.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e04513",
      "metadata": {
        "id": "56e04513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed654fbd-a03a-44a9-da52-3ac42c159db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size: 23.84 MB\n",
            "Size: 95.12 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "def print_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print(f'Size: {os.path.getsize(\"temp.p\")/1e6:.2f} MB')\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_model_size(qmodel)\n",
        "print_model_size(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(qmodel.state_dict(), \"quantized_res50_c100.pth\")"
      ],
      "metadata": {
        "id": "TxsdFuMrPleV"
      },
      "id": "TxsdFuMrPleV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJ4iwacl2pQw"
      },
      "id": "JJ4iwacl2pQw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}